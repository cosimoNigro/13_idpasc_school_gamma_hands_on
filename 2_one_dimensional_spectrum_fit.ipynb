{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd0c3537",
   "metadata": {},
   "source": [
    "# 2. Multi-instrument one-dimensional analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474114b3",
   "metadata": {},
   "source": [
    "In the last notebook, we have extracted counts vs energy, but this is a physical quantity (or information) filtered through our detector system. What we really aim at estimating is the gamma-ray flux of the source, in particular, the flux over a large band in energy (spectrum)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dfe167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - basic dependencies\n",
    "import numpy as np\n",
    "import astropy.units as u\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# - Gammapy dependencies\n",
    "from gammapy.datasets import SpectrumDatasetOnOff, Datasets\n",
    "from gammapy.modeling import Parameter\n",
    "from gammapy.modeling.models import (\n",
    "    SpectralModel,\n",
    "    PowerLawSpectralModel,\n",
    "    LogParabolaSpectralModel,\n",
    "    SkyModel,\n",
    "    create_crab_spectral_model,\n",
    ")\n",
    "from gammapy.modeling import Fit\n",
    "from gammapy.estimators import FluxPointsEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91240682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read image\n",
    "img = mpimg.imread(\"figures/crab_sed_hess.png\")\n",
    "# display image\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.imshow(img)\n",
    "ax.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c42a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read image\n",
    "img = mpimg.imread(\"figures/crab_sed_magic.png\")\n",
    "# display image\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.imshow(img)\n",
    "ax.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e00bcd",
   "metadata": {},
   "source": [
    "To obtain a measurement of the specturm, it is commonly assumed that a simple analytical function describes the gamma-ray (differential) flux vs energy. The most common example is a power-law:\n",
    "\n",
    "$$\n",
    "\\frac{{\\rm d}\\phi}{{\\rm d}E}(E; \\Phi_0, \\Gamma, E_0)\\,[{\\rm TeV}^{-1}\\,{\\rm cm}^{-2}\\,{\\rm s}^{-1}] = \n",
    "\\Phi_0 \\left(\\frac{E}{E_0}\\right)^{-\\Gamma}.\n",
    "$$\n",
    "\n",
    "Note that we have a _continuous_ dependency on the energy (we want to measure the flux as a function of the energy) and we have a _parametric_ dependency on few parameters that describe our analytical spectrum, in this case the normalisation $\\Phi_0$, the reference energy, $E_0$, and the spectral index, $\\Gamma$. From now on, we will represent all the model parameters with an array $\\hat{\\theta}$.\n",
    "\n",
    "Let us now plot some of the examples of analytical spectra available in `Gammapy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e166cb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_bounds = [100 * u.GeV, 10 * u.TeV]\n",
    "pwl = PowerLawSpectralModel()\n",
    "pwl.plot(energy_bounds, label=\"power law\")\n",
    "lp = LogParabolaSpectralModel(\n",
    "    amplitude=7e-11 * u.Unit(\"TeV-1 cm-2 s-1\"), reference=100 * u.GeV\n",
    ")\n",
    "lp.plot(energy_bounds, label=\"log parabola\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5f6d31",
   "metadata": {},
   "source": [
    "How can we adjust the parameters $\\hat{\\theta}$ of the analytical spectrum to the counts that we have extracted? That's where the IRF come into place. The IRF allow us to go from gamma-ray flux to instrument counts and vice versa. By folding (i.e. convolving) the analytical flux model with the response of the system we can obtain counts vs energy. We basically transform the absolute flux quantity relative to the detector. The number of model (or _predicted_) counts in a given energy bin $\\Delta E'$ is:\n",
    "\n",
    "$$\n",
    "g_{i}(\\hat{\\theta}) = \n",
    "    t_{\\rm eff} \\int_{\\Delta E'} {\\rm d}E' \\int_{0}^{\\infty} {\\rm d}E \\;\n",
    "    A_{\\rm eff}(E) M(E'|E) \\frac{{\\rm d}\\phi}{{\\rm d}E}(E; \\hat{\\theta}),\n",
    "$$\n",
    "\n",
    "where $A_{\\rm eff}(E)$ represent the effective area and $M(E'|E)$ the energy dispersion, i.e. the PDF of the energy estimator.\n",
    "\n",
    "How we decide which (predicted) counts better describe our model? With a likelihood, we assume that the counts in each bin are described by Poissonian statistics. The total likelihood for our dataset, accounting for the observed and estimated counts in each energy bin, reads:\n",
    "\n",
    "$$ \n",
    "\\mathcal{L}(\\hat{\\theta}) = \n",
    "    \\Pi_{i=1}^{N} {\\rm Pois}(g_i(\\hat{\\theta}) + b_i; N_{{\\rm on}, i}) {\\rm Pois}(b_i / \\alpha; N_{{\\rm off}, i})\n",
    "$$\n",
    "\n",
    "where $g_i$ is the number of predicted counts, $\\alpha$ the ratio between the on and off region exposures. $b_i$, the number of background counts, is typically treated as a nuisance parameter. The likelihood is maximised by varying the spectral parameters $\\hat{\\theta}$, and hence the number of predicted counts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e5ab86",
   "metadata": {},
   "source": [
    "## 2.1. Predicting the counts for a given data set\n",
    "Let us load the data sets we created in the previous notebook. We select also an energy range compatible with the instruments performance and with the range of events observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72f647c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# H.E.S.S. data sets\n",
    "obs_ids_hess = [23523, 23526, 23559, 23592]\n",
    "# declare the energy range to be used for the fitting\n",
    "e_min_hess = 0.66 * u.TeV\n",
    "e_max_hess = 30 * u.TeV\n",
    "\n",
    "# load H.E.S.S. spectral datasets\n",
    "datasets_hess = Datasets()\n",
    "for obs_id in obs_ids_hess:\n",
    "    dataset = SpectrumDatasetOnOff.read(f\"results/spectra/hess/pha_obs_{obs_id}.fits\")\n",
    "    # set the proper energy ranges\n",
    "    dataset.mask_fit = dataset.counts.geom.energy_mask(e_min_hess, e_max_hess)\n",
    "    datasets_hess.append(dataset)\n",
    "\n",
    "\n",
    "# MAGIC data sets\n",
    "obs_ids_magic = [5029747, 5029748]\n",
    "# declare the energy range to be used for the fitting\n",
    "e_min_magic = 0.08 * u.TeV\n",
    "e_max_magic = 10 * u.TeV\n",
    "\n",
    "# load MAGIC spectral datasets\n",
    "datasets_magic = Datasets()\n",
    "for obs_id in obs_ids_magic:\n",
    "    dataset = SpectrumDatasetOnOff.read(f\"results/spectra/magic/pha_obs_{obs_id}.fits\")\n",
    "    # set the proper energy ranges\n",
    "    dataset.mask_fit = dataset.counts.geom.energy_mask(e_min_magic, e_max_magic)\n",
    "    datasets_magic.append(dataset)\n",
    "\n",
    "\n",
    "# LST data sets\n",
    "obs_ids_lst = [7253, 7254, 7255, 7256, 7274, 7275, 7276, 7277]\n",
    "# declare the energy range to be used for the fitting\n",
    "e_min_lst = 0.06 * u.TeV\n",
    "e_max_lst = 30 * u.TeV\n",
    "\n",
    "# load LST spectral datasets\n",
    "datasets_lst = Datasets()\n",
    "for obs_id in obs_ids_lst:\n",
    "    dataset = SpectrumDatasetOnOff.read(f\"results/spectra/lst/pha_obs_{obs_id}.fits\")\n",
    "    # set the proper energy ranges\n",
    "    dataset.mask_fit = dataset.counts.geom.energy_mask(e_min_lst, e_max_lst)\n",
    "    datasets_lst.append(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3b07e1",
   "metadata": {},
   "source": [
    "Once we have the data sets we can specify a model for them, `Gammapy` will automatically convolve it with the response of the system and compute (predict) the counts. Here an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b63b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model to be fitted\n",
    "spectral_model = LogParabolaSpectralModel(\n",
    "    amplitude=5e-12 * u.Unit(\"TeV-1 cm-2 s-1\"),\n",
    "    reference=1 * u.TeV,\n",
    "    alpha=2.3 * u.Unit(\"\"),\n",
    "    beta=0.1 * u.Unit(\"\"),\n",
    ")\n",
    "# trick to facilitate ULs computation\n",
    "spectral_model.amplitude.min = 1e-20\n",
    "spectral_model.amplitude.max = 1e-5\n",
    "print(spectral_model)\n",
    "\n",
    "model = SkyModel(spectral_model=spectral_model, name=\"CrabNebula\")\n",
    "\n",
    "datasets_lst.models = [model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5839be9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_lst[0].plot_excess()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87310c0d",
   "metadata": {},
   "source": [
    "We can also check the contribution of this data set to the total likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513cdada",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_lst[0].stat_sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f37f94",
   "metadata": {},
   "source": [
    "As we can see, the counts predicted by the model we specified for the data set are one order of magnitude below the observed source counts. \n",
    "\n",
    "To get a feeling of how the fit work, let us go back to the definition of the spectral analytical function and change the amplitude parameter to `5e-11 * u.Unit(\"TeV-1 cm-2 s-1\")`. What happens to the predicted counts? And what happens to the likelihood statistics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cafc77-56f1-4396-b575-56f8807014eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_lst.models[0].spectral_model.amplitude.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727c24ae-707c-4769-a7b8-c67b98c79a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_lst.models[0].spectral_model.amplitude.value = 5e-11\n",
    "\n",
    "datasets_lst[0].plot_excess()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb14adaa-99a2-4726-a6b4-97cfb64b15ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_lst[0].stat_sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dbb774-2911-4b5d-aef9-b53fd3057f93",
   "metadata": {},
   "source": [
    "\n",
    "You have now an intuition of how the fitting routine work. The parameters will be changed until the best match between observed and predicted counts is observed. This agreement is statistically quantified by the likelihood, which is what is actually maximised."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7bc3c3",
   "metadata": {},
   "source": [
    "## 2.2. Spectrum of the Crab Nebula as seen by LST-1\n",
    "The likelihood maximisation is performed by the `gammapy.Fit` class using the `gammapy.Dataset` and the model we have asigned to it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d3544f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the fit!\n",
    "fit = Fit()\n",
    "results = fit.run(datasets=datasets_lst)\n",
    "print(results)\n",
    "print(spectral_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9550523",
   "metadata": {},
   "source": [
    "We can check, after the optimisation, how the predicted counts adapt to the observed one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d92981",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax_spectrum, ax_residuals = datasets_lst[0].plot_fit()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b39e642",
   "metadata": {},
   "source": [
    "and check also the value of the likelihood per each of the data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7054cae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_lst[0].stat_sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad745f8",
   "metadata": {},
   "source": [
    "We can now plot the spectrum obtained by our fitting procedure. It is common in high-energy astrophysics, to represent instead of the differential flux the Spectral Energy Distribution (SED) obtained as $E^2\\frac{{\\rm d}\\phi}{{\\rm d}E} [{\\rm TeV}^{-1}\\,{\\rm cm}^{-2}\\,{\\rm s}^{-1}]$ that represent the how the emitted power is distributed over the electromagnetic spectrum. We compare the results we have obtained with a theoretical model of the SED and with another measurement performed by MAGIC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ad9a02-a19a-4284-9926-b8470431e76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "plot_kwargs = {\n",
    "    \"sed_type\": \"e2dnde\",\n",
    "    \"yunits\": u.Unit(\"TeV cm-2 s-1\"),\n",
    "    \"xunits\": u.GeV,\n",
    "}\n",
    "\n",
    "energy_range = [e_min_lst, e_max_lst]\n",
    "\n",
    "spectral_model.plot(\n",
    "    energy_range,\n",
    "    ax=ax,\n",
    "    color=\"crimson\",\n",
    "    ls=\"-\",\n",
    "    label=\"LST\",\n",
    "    **plot_kwargs,\n",
    ")\n",
    "spectral_model.plot_error(\n",
    "    energy_range, ax=ax, facecolor=\"crimson\", alpha=0.4, **plot_kwargs\n",
    ")\n",
    "\n",
    "crab_meyer = create_crab_spectral_model(\"meyer\")\n",
    "crab_meyer.plot(\n",
    "    energy_range,\n",
    "    ax=ax,\n",
    "    label=\"Meyer et al. (2010)\",\n",
    "    color=\"k\",\n",
    "    ls=\"--\",\n",
    "    **plot_kwargs,\n",
    ")\n",
    "\n",
    "crab_magic = create_crab_spectral_model(\"magic_lp\")\n",
    "crab_magic.plot(\n",
    "    energy_range,\n",
    "    ax=ax,\n",
    "    label=\"MAGIC Collaboration (2015)\",\n",
    "    color=\"dodgerblue\",\n",
    "    ls=\"--\",\n",
    "    **plot_kwargs,\n",
    ")\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "ax.set_xlabel(r\"$E\\,/\\,{\\rm GeV}$\")\n",
    "ax.set_ylabel(\n",
    "    r\"$E^2 {\\rm d}\\phi/{\\rm d}E\\,/\\,({\\rm TeV}\\,{\\rm cm}^{-2}\\,{\\rm s}^{-1})$\"\n",
    ")\n",
    "ax.set_ylim([8e-13, 2e-10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8537228e-0641-48eb-98e0-cb86f07782a6",
   "metadata": {},
   "source": [
    "Finally we also compute spectral data points or _flux points_. They are basically a flux measurement over different energy bins. Broadly speaking, they have two objectives:\n",
    "1) when we fit the broad-band spectrum via the likelihood maximisation - as we have just shown - we are assuming that the entire spectrum is described by a single analytic smooth functions. This type of analysis is therefore not sensitive to any sharp feature in the spectrum;\n",
    "2) we are adopting an analytical function to provide a broad-band flux measurements, yet, at a later stage, other astrophysicists might want to fit a physical model to our gamma-ray data. In order to do so they should have access to the data sets (counts + IRF) that we are using. In case this data are proprietary we can provide a simplified and easier to handle flux measurements.\n",
    "\n",
    "To compute flux points, Gammapy starts from the best-fit spectrum obtained from the broad-band likelihood fit and re-adjusts it spearately to the events within each energy bin. Note theat only the amplitude of the spectrum is re-fitted. Basically, the spectrum we obtained from the broad-band likelihood fit is scaled up and down to adjust independently to the counts in each energy bin.\n",
    "\n",
    "Let us use the same binning we have used in estimated energies and select an interval compatible with what used in the likelihood fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a9f560-fe31-48f6-b92f-305d70209b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_lst[0].counts.geom.axes[\"energy\"].edges[4:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e691d685-89f4-4be2-914a-214ef0d375e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_edges = datasets_lst[0].counts.geom.axes[\"energy\"].edges[4:-2]\n",
    "fpe_lst = FluxPointsEstimator(\n",
    "    energy_edges=energy_edges, source=\"CrabNebula\", selection_optional=\"all\"\n",
    ")\n",
    "flux_points_lst = fpe_lst.run(datasets=datasets_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c10365-eb3b-4249-aa0d-3faecbae9708",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "flux_points_lst.plot(ax=ax, sed_type=\"e2dnde\", color=\"darkorange\", label=\"flux points\")\n",
    "flux_points_lst.plot_ts_profiles(ax=ax, sed_type=\"e2dnde\")\n",
    "spectral_model.plot(\n",
    "    energy_range,\n",
    "    ax=ax,\n",
    "    color=\"crimson\",\n",
    "    ls=\"--\",\n",
    "    lw=2,\n",
    "    sed_type=\"e2dnde\",\n",
    "    label=\"broad-band likelihood fit\",\n",
    ")\n",
    "ax.set_xlim([40, 2.5e4])\n",
    "ax.set_xlabel(r\"$E\\,/\\,{\\rm GeV}$\")\n",
    "ax.set_ylabel(\n",
    "    r\"$E^2 {\\rm d}\\phi/{\\rm d}E\\,/\\,({\\rm TeV}\\,{\\rm cm}^{-2}\\,{\\rm s}^{-1})$\"\n",
    ")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1fe7ca",
   "metadata": {},
   "source": [
    "## 2.3. Exercises for this tutorial\n",
    "\n",
    "### Exercise 2.3.1.\n",
    "Obtain a multi-instrument measurement of the Crab Nebula spectrum by fitting the datasets from all the instruments at once. As LST-1 data contain much more staitstics than the others, use only the first run of that data set. Compute the flux points for each instrument and overplot them on the final spectrum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c250ac51-bee7-4ade-a971-7eb34e638b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./solutions/solution_notebook_2.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
